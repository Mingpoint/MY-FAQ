##### 消息丢失有三种情况
1. product(生成端)丢失： 为了减少网络IO，生产端的request请求会被打包成一个批次，异步发送。
   在正常情况下，客户端的异步调用可以通过callback来处理消息发送失败或者超时的情况，
   这就导致如果在这期间发生了生产端内存不够，或者producer被异常停止，就有可能丢失。
   处理思路：
   - 异步改为同步发送，吞吐量受限.
   - 扩大内存，防止生成端内存不足的情况.
   - 先把要发送的数据写入表中，再由其他的异步线程发送.
2. broker端丢失：为了提高刷盘写入效率，kafka 采用了异步批量刷盘的做法；即一定量和时间间隔进行刷盘
   ，如果期间发生了宕机，则有可能丢失数据。
    处理思路：kafka通过producer和broker协同处理单个broker丢失参数的情况。一旦producer发现broker消息丢失，即可自动进行retry。
    除非retry次数超过阀值（可配置），消息才会丢失。此时需要生产者客户端手动处理该情况。那么producer是如何检测到数据丢失的呢？是通过ack机制，类似于http的三次握手的方式。
    - acks = 0,表示producer不等待broker的响应，就直接返回了,效率最高，但是可能丢失消息
    - acks = 1，表示producer等待broker leader 刷盘完成后就响应，不等待其他follower，leader 宕机可能会丢失消息。
    - acks = 2，表示producer等待broker leader和follower都刷完盘子后响应，不会丢失数据。
3. consumer端丢失消息：
   - consumer 端处理流程，拉取消息，处理消息，提交 offset. 提交offset 分为手动提交和自动提交。一般出问题的都是自动提交。 
   - 自动提交：每个一段时间自动提交一次offset，如果处理流程超过了自动提交的时间间隔，但是消费不成功，可能就会丢失消息。
   - 处理思路：改为手动提交，这样者少能保证至少消费一次(at least once)，但是可能会存在重复消费问题。